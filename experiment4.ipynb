{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81129346-ad4a-48ff-844d-3573e53b35de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b033c-b254-4f21-b012-a059663f4610",
   "metadata": {},
   "source": [
    "The aim of Assignment 1 is to implement a concept learner and to verify that it works as expected using the following:  \n",
    "**Group assignment:** Max 2 students  \n",
    "\n",
    "**Prerequisite reading:** Chapter 4 in the main literature  \n",
    "\n",
    "**Language:** Python (it is not permitted to use any existing code except the standard libraries,  you are allowed to use standard libraries and other libraries that help you preprocess the data, etc.)  \n",
    "\n",
    "**Data:** Spambase Dataset, https://archive.ics.uci.edu/ml/datasets/SpambaseLinks to an external site.  \n",
    "\n",
    "**Algorithm:** Algorithm 4.1 and either Algorithm 4.2 or 4.3 in the main literature (it is not permitted to use already implemented algorithms, you must implement  Algorithm 4.1 and either Algorithm 4.2 or 4.3 yourselves.)  \n",
    "\n",
    "**Procedure**  \n",
    "Identify a suitable preprocessing method for data transformation (continuous to discrete).  \n",
    "\n",
    "<ins>Compute:</ins>\n",
    "1) the size of possible instances\n",
    "2) the size of hypothesis space (the number of possible extensions)\n",
    "3) the number of possible conjunctive concepts according to the descriptions in Section 4.1 of the main literature\n",
    "\n",
    "Implement the algorithm and verify that it works as expected.  \n",
    "Compute the accuracy of the model and report the generated model, i.e., the conjunctive rule.  \n",
    "\n",
    "**Written report**  \n",
    "Template: The IEEE conference template and citation style should be followed (templatesLinks to an external site. in MS word and LaTeX).  \n",
    "Language:  English without spelling mistakes.  \n",
    "Style: Clear.  \n",
    "Format: PDF.  \n",
    "Page limit: 1 page excluding references (no abstract should be included).  \n",
    "\n",
    "**Code**  \n",
    "Provide meaningful comments for different blocks of the code.  \n",
    "A *README.TXT* file must clearly state exactly how to execute the code and any necessary setups.  \n",
    "\n",
    "**Submission**  \n",
    "Make sure to include your names in the report and the code.  \n",
    "The report must be submitted as a PDF separately (not to be included in the ZIP file).  \n",
    "Code and additional files related to implementation must be archived using ZIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320a9bb5-45a3-4d9f-8e29-26385622fe6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75583e4e-dd01-4da4-a4a4-9b46aface3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configurations\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 12)\n",
    "plt.rcParams['figure.constrained_layout.use'] = True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddecf04-5dda-464b-8843-96daea7be73e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns are saved in the data/names.txt file. Here we all entries without the newline character in a list.\n",
    "with open(\"data/names.txt\", \"r\") as f:\n",
    "    columns = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f913d5-72ff-440e-acdc-215574b2cf67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data/spambase.data with read_csv method and set names of columns equal to the list we created above. \n",
    "df = pd.read_csv(\"data/spambase.data\", names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a47bb5-234a-4811-9bcb-ca74ee661a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.00            0.00  ...         0.00        0.000   \n",
       "1              0.00            0.94  ...         0.00        0.132   \n",
       "2              0.64            0.25  ...         0.01        0.143   \n",
       "3              0.31            0.63  ...         0.00        0.137   \n",
       "4              0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0          0.0        0.778         0.000        0.000   \n",
       "1          0.0        0.372         0.180        0.048   \n",
       "2          0.0        0.276         0.184        0.010   \n",
       "3          0.0        0.137         0.000        0.000   \n",
       "4          0.0        0.135         0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read head of table.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef494f-9547-43f4-b4f5-c0678730bc68",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "Asserting that our columns match the described columns in the spambase.names file. If the assertion fails we receive an error, if not, it passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65aaa6b0-5e00-4f9b-a226-7d74ca247659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert whether theres 48 attributes of type word_freq_WORD\n",
    "assert len([col for col in [cols for cols in df.columns] if \"word_freq\" in col]) == 48\n",
    "# assert whether theres 48 attributes of type char_freq_CHAR\n",
    "assert len([col for col in [cols for cols in df.columns] if \"char_freq\" in col]) == 6\n",
    "# assert whether theres 1 attribute of type capital_run_length_average\n",
    "assert len([col for col in [cols for cols in df.columns] if \"capital_run_length_average\" in col]) == 1\n",
    "# assert whether theres 1 attribute of type capital_run_length_longest\n",
    "assert len([col for col in [cols for cols in df.columns] if \"capital_run_length_longest\" in col]) == 1\n",
    "# assert whether theres 1 attribute of type capital_run_length_total\n",
    "assert len([col for col in [cols for cols in df.columns] if \"capital_run_length_total\" in col]) == 1\n",
    "# assert whether the spam column only contains bools (1s or 0s).\n",
    "assert (df.is_spam.unique() == [1, 0]).all()\n",
    "# assert whether theres 58 cols\n",
    "assert df.columns.nunique() == 58"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee59f7-2351-4056-a8b0-03c417eb13ee",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2ca76-e2e6-44bc-95b2-1d10c6861e3b",
   "metadata": {},
   "source": [
    "for i, column in enumerate(df.columns[:25], 1):\n",
    "    plt.subplot(20, 5, i)\n",
    "    sns.histplot(df[column], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f84f0-7c41-4019-a376-c62c18838d05",
   "metadata": {},
   "source": [
    "for i, column in enumerate(df.columns[25:], 1):\n",
    "    plt.subplot(20, 5, i)\n",
    "    sns.histplot(df[column], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1eb098-bb36-467b-bd67-d43cc1ffee28",
   "metadata": {},
   "source": [
    "Based on above graphs we can conclude that the data set is very right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563eed73-09b0-4366-823c-b040b6bf9350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9c8dc-405f-4ab7-8a97-83f4217cafa8",
   "metadata": {},
   "source": [
    "Duplicates dont effect the accuracy of concept learning models, however it will increase the time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6389a467-f6cd-4382-895d-fcd6d509ab81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.605955\n",
       "1    0.394045\n",
       "Name: is_spam, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_spam.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54278cf6-e712-4410-bb60-5328ec1d0c1b",
   "metadata": {},
   "source": [
    "The data is somewhat unbalanced with roughly 60% ham rate and a 40% spam rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fa030b-4748-4f72-baf2-b207a13febe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9196c2-a624-4ec2-8421-fc75c296c627",
   "metadata": {},
   "source": [
    "No missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbe3aa-24c0-4596-becc-7f2dba89805a",
   "metadata": {},
   "source": [
    "## Data munging/wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504e9f98-2ec9-4331-b593-e221ec1d0b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                float64\n",
       "word_freq_address             float64\n",
       "word_freq_all                 float64\n",
       "word_freq_3d                  float64\n",
       "word_freq_our                 float64\n",
       "word_freq_over                float64\n",
       "word_freq_remove              float64\n",
       "word_freq_internet            float64\n",
       "word_freq_orders              float64\n",
       "word_freq_mail                float64\n",
       "word_freq_receive             float64\n",
       "word_freq_will                float64\n",
       "word_freq_people              float64\n",
       "word_freq_report              float64\n",
       "word_freq_addresses           float64\n",
       "word_freq_free                float64\n",
       "word_freq_business            float64\n",
       "word_freq_email               float64\n",
       "word_freq_you                 float64\n",
       "word_freq_credit              float64\n",
       "word_freq_your                float64\n",
       "word_freq_font                float64\n",
       "word_freq_000                 float64\n",
       "word_freq_money               float64\n",
       "word_freq_hp                  float64\n",
       "word_freq_hpl                 float64\n",
       "word_freq_george              float64\n",
       "word_freq_650                 float64\n",
       "word_freq_lab                 float64\n",
       "word_freq_labs                float64\n",
       "word_freq_telnet              float64\n",
       "word_freq_857                 float64\n",
       "word_freq_data                float64\n",
       "word_freq_415                 float64\n",
       "word_freq_85                  float64\n",
       "word_freq_technology          float64\n",
       "word_freq_1999                float64\n",
       "word_freq_parts               float64\n",
       "word_freq_pm                  float64\n",
       "word_freq_direct              float64\n",
       "word_freq_cs                  float64\n",
       "word_freq_meeting             float64\n",
       "word_freq_original            float64\n",
       "word_freq_project             float64\n",
       "word_freq_re                  float64\n",
       "word_freq_edu                 float64\n",
       "word_freq_table               float64\n",
       "word_freq_conference          float64\n",
       "char_freq_;                   float64\n",
       "char_freq_(                   float64\n",
       "char_freq_[                   float64\n",
       "char_freq_!                   float64\n",
       "char_freq_$                   float64\n",
       "char_freq_#                   float64\n",
       "capital_run_length_average    float64\n",
       "capital_run_length_longest      int64\n",
       "capital_run_length_total        int64\n",
       "is_spam                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191a4e3-5a9b-40a8-9459-33b71ab924ee",
   "metadata": {},
   "source": [
    "Very big data types. I'll reduce the data size after discretization for all columns to reduce the space complexity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8aecf57-fccd-4021-a56c-af06fde3f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(df_: pd.DataFrame, nbins: int, columns_: list[str], class_column: str) -> pd.DataFrame:\n",
    "    \"\"\"discretizes dataframe into n_bins, joins the class column post-discretization and lastly converts the table data type into 8-bit integer.\"\"\"\n",
    "    return (\n",
    "        pd\n",
    "        .DataFrame(\n",
    "            KBinsDiscretizer(n_bins=nbins, encode='ordinal', strategy='kmeans')\n",
    "            .fit_transform(df_), \n",
    "            columns=columns_)\n",
    "        .join(df[class_column])\n",
    "        .astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e222cfc-0f35-48fd-b5eb-bce6399bb4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_orders</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0                  0              1             0   \n",
       "1               0                  0              1             0   \n",
       "2               0                  0              1             0   \n",
       "3               0                  0              0             0   \n",
       "4               0                  0              0             0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0               0                 0                   0   \n",
       "1              0               0                 0                   0   \n",
       "2              1               0                 0                   0   \n",
       "3              0               0                 0                   0   \n",
       "4              0               0                 0                   0   \n",
       "\n",
       "   word_freq_orders  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0                 0               0  ...            0            0   \n",
       "1                 0               1  ...            0            0   \n",
       "2                 1               0  ...            0            0   \n",
       "3                 0               0  ...            0            0   \n",
       "4                 0               0  ...            0            0   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$   char_freq_#  \\\n",
       "0            0            0             0            0   \n",
       "1            0            0             0            0   \n",
       "2            0            0             0            0   \n",
       "3            0            0             0            0   \n",
       "4            0            0             0            0   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           1   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                         0        1  \n",
       "1                         0        1  \n",
       "2                         0        1  \n",
       "3                         0        1  \n",
       "4                         0        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disc = (\n",
    "    discretization(\n",
    "        df_=df.iloc[:, :-1], \n",
    "        nbins=3, \n",
    "        columns_=columns[:-1], \n",
    "        class_column=\"is_spam\"))\n",
    "\n",
    "df_disc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7315de-3c60-40b5-b41e-08e7b03090ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert new data type for entire data frame is 8-bit integer\n",
    "assert (df_disc.dtypes == np.int8).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae4eb2-edb6-4185-abe7-2818244a3056",
   "metadata": {},
   "source": [
    "# display distribution for all columns\n",
    "for i, column in enumerate(df_disc.columns[:25], 1):\n",
    "    plt.subplot(20, 5, i)\n",
    "    sns.histplot(df_disc[column], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95d726-d294-4a83-bce1-2caf8167d340",
   "metadata": {},
   "source": [
    "for i, column in enumerate(df_disc.columns[25:], 1):\n",
    "    plt.subplot(20, 5, i)\n",
    "    sns.histplot(df_disc[column], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ab1a7b-a534-4995-9559-48081575aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                3\n",
       "word_freq_address             3\n",
       "word_freq_all                 3\n",
       "word_freq_3d                  3\n",
       "word_freq_our                 3\n",
       "word_freq_over                3\n",
       "word_freq_remove              3\n",
       "word_freq_internet            3\n",
       "word_freq_orders              3\n",
       "word_freq_mail                3\n",
       "word_freq_receive             3\n",
       "word_freq_will                3\n",
       "word_freq_people              3\n",
       "word_freq_report              3\n",
       "word_freq_addresses           3\n",
       "word_freq_free                3\n",
       "word_freq_business            3\n",
       "word_freq_email               3\n",
       "word_freq_you                 3\n",
       "word_freq_credit              3\n",
       "word_freq_your                3\n",
       "word_freq_font                3\n",
       "word_freq_000                 3\n",
       "word_freq_money               3\n",
       "word_freq_hp                  3\n",
       "word_freq_hpl                 3\n",
       "word_freq_george              3\n",
       "word_freq_650                 3\n",
       "word_freq_lab                 3\n",
       "word_freq_labs                3\n",
       "word_freq_telnet              3\n",
       "word_freq_857                 3\n",
       "word_freq_data                3\n",
       "word_freq_415                 3\n",
       "word_freq_85                  3\n",
       "word_freq_technology          3\n",
       "word_freq_1999                3\n",
       "word_freq_parts               3\n",
       "word_freq_pm                  3\n",
       "word_freq_direct              3\n",
       "word_freq_cs                  3\n",
       "word_freq_meeting             3\n",
       "word_freq_original            3\n",
       "word_freq_project             3\n",
       "word_freq_re                  3\n",
       "word_freq_edu                 3\n",
       "word_freq_table               3\n",
       "word_freq_conference          3\n",
       "char_freq_;                   3\n",
       "char_freq_(                   3\n",
       "char_freq_[                   3\n",
       "char_freq_!                   3\n",
       "char_freq_$                   3\n",
       "char_freq_#                   3\n",
       "capital_run_length_average    3\n",
       "capital_run_length_longest    3\n",
       "capital_run_length_total      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas series with bucket amount per feature\n",
    "(df_disc\n",
    " .iloc[:, :-1]\n",
    " .apply(pd.unique, axis=0)\n",
    " .apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec6480-941c-4a8f-8cb1-b520ef252fbc",
   "metadata": {},
   "source": [
    "### Instance Space\n",
    "\n",
    "All possible or describable instances, whether they are present in our data set or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad0f4874-bfd2-4af0-b263-0af2fe65add3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1918675807427425827"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(df_disc\n",
    " .iloc[:, :-1]\n",
    " .apply(pd.unique, axis=0)\n",
    " .apply(len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ca184-15ff-4ef1-8b61-0c996669e384",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hypothesis Space\n",
    "The possible permutations of a class. Take the amount of classes to the power of the instance space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27453855-38c4-4665-8a06-445b9574660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** (np.prod(df_disc\n",
    "            .iloc[:, :-1]\n",
    "            .apply(pd.unique, axis=0)\n",
    "            .apply(len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9defc-972c-4f42-9e93-92aef4195755",
   "metadata": {},
   "source": [
    "The hypothesis space is too large to be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c6cda-2bae-4c27-bde5-73ac74572561",
   "metadata": {},
   "source": [
    "### Conjunctive space\n",
    "the number of possible conjunctive concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb1f0270-2299-45c7-a876-7f2ce9cf79a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(df_disc\n",
    " .iloc[:, :-1]\n",
    " .apply(pd.unique, axis=0)\n",
    " .apply(len) + 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c30df-8101-4079-a6ca-d6dceb2dd0a3",
   "metadata": {},
   "source": [
    "Too large of a number to be computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3676c37-0c52-4386-be8e-26b36b01b241",
   "metadata": {},
   "source": [
    "### Concept-learning algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6492c305-3dc9-4f10-abea-669dc9c9865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal module. an objective orientat implementation of concept learning\n",
    "from concept_learner import ConceptLearner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7533e185-7a3c-4f69-90df-c59958e0e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ConceptLearner(df_disc, \"is_spam\")\n",
    "cl.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c82616-b867-46fb-a91c-3ff2913443b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37455a08-f5ad-42a1-9fbe-c09cff5daaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6112920738327905"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0260add-9ec5-4e92-a8bc-b33301ebf286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4512040557667934"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.true_positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "726976c8-a5b6-4d4f-ba03-ecd6565bbb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1\n",
       "Actual             \n",
       "0          130  433\n",
       "1            2  356"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f349394b-fd25-43f1-a270-ac5487f7ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_freq_george = 0 ∧word_freq_lab = 0 ∧word_freq_telnet = 0 ∧word_freq_415 = 0 ∧word_freq_85 = 0 ∧word_freq_parts = 0 ∧word_freq_cs = 0 ∧word_freq_meeting = 0 ∧word_freq_project = 0 ∧word_freq_conference = 0 ∧char_freq_! = 0 ∧"
     ]
    }
   ],
   "source": [
    "cl.get_conjective_rule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
